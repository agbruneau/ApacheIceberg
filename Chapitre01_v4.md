# Chapitre 1 : Le Monde du Lakehouse Apache Iceberg

> _"La meilleure architecture est celle qui peut Ã©voluer sans tout reconstruire."_

En tant qu'architecte de donnÃ©es, vous avez probablement connu l'Ã©poque des migrations massives, des nuits blanches pour rÃ©Ã©crire des pipelines entiers, et des dÃ©bats sans fin entre "tout dans l'entrepÃ´t" et "tout dans le lac". Apache Iceberg met fin Ã  ces faux dilemmes. Ce chapitre explique pourquoi.

## 1.1 Qu'est-ce qu'un Data Lakehouse ?

### L'Histoire de Trois Architectures

Pour comprendre le Lakehouse, retraÃ§ons l'histoire Ã  travers un cas concret : imaginons une entreprise de streaming vidÃ©o (appelons-la "StreamCo") qui gÃ¨re les donnÃ©es de visionnage de millions d'utilisateurs.

#### Chapitre 1 : L'Ãˆre du Data Warehouse (1995-2010)

**La promesse** : Une source unique de vÃ©ritÃ©, structurÃ©e et fiable.

StreamCo stocke dans Teradata :

- Tables `utilisateurs` (10 millions de lignes)
- Tables `visionnages` (100 millions de lignes/mois)
- Tables `factures` (5 millions de lignes/mois)

**Ce qui fonctionne** :

- RequÃªtes SQL ultra-rapides pour le reporting financier
- Transactions ACID garantissant la cohÃ©rence
- Outils BI connectÃ©s facilement (Tableau, PowerBI)

**Ce qui bloque** :

- CoÃ»t : 500 000$/an pour 20 To
- RigiditÃ© : Ajouter une colonne = 3 semaines de planification
- Impossible de stocker les logs d'application (donnÃ©es semi-structurÃ©es JSON)

```mermaid
graph TD
    A[Sources OpÃ©rationnelles] -->|ETL Nightly| B[Data Warehouse]
    B --> C[Rapports BI]
    B --> D[Dashboards]

    E[Logs Application] -.->|RejetÃ©<br/>Non structurÃ©| B
    F[Clics Web] -.->|RejetÃ©<br/>Trop volumineux| B

    style B fill:#90EE90
    style E fill:#FFB6C6
    style F fill:#FFB6C6
```

#### Chapitre 2 : L'Ãˆre du Data Lake (2010-2018)

**La promesse** : Stockez tout, Ã  bas coÃ»t, analysez plus tard.

StreamCo migre vers Hadoop/HDFS puis AWS S3 :

- Logs applicatifs : 500 Go/jour en JSON
- Ã‰vÃ©nements de clic : 1 To/jour en format Avro
- CoÃ»t : 30 000$/an pour 1 Po

**Ce qui fonctionne** :

- Data scientists peuvent explorer librement
- Machine Learning sur donnÃ©es brutes (recommandations vidÃ©o)
- CoÃ»t de stockage divisÃ© par 10

**Ce qui bloque** :

```python
# Le cauchemar du Data Engineer
spark.read.parquet("s3://lake/visionnages/year=2023/month=*/")
# âŒ Certains fichiers corrompus (jobs qui ont crashÃ©)
# âŒ Doublons (jobs relancÃ©s sans idempotence)
# âŒ Impossible de faire UPDATE/DELETE (RGPD !)
```

Le lac devient un **marÃ©cage** :

- Pas de transactions â†’ donnÃ©es corrompues
- Pas d'Ã©volution de schÃ©ma â†’ cassures de pipeline
- Pas de gouvernance â†’ impossible de se conformer aux rÃ©glementations

#### Chapitre 3 : L'Ãˆre du Lakehouse (2020-prÃ©sent)

**La promesse** : La fiabilitÃ© de l'entrepÃ´t sur l'Ã©conomie du lac.

StreamCo adopte Apache Iceberg :

- MÃªme stockage S3 (Ã©conomique)
- Transactions ACID sur les fichiers
- Support UPDATE/DELETE pour la conformitÃ©

```sql
-- Maintenant possible avec Iceberg :
DELETE FROM visionnages
WHERE user_id = 'gdpr_request_12345';
-- âœ… OpÃ©ration atomique, aucun fichier corrompu
```

### Le Lakehouse en un Graphique

```mermaid
graph TB
    subgraph Storage["ğŸ’¾ Stockage Ã‰conomique (S3/ADLS/GCS)"]
        FILES[Fichiers Parquet/ORC/Avro]
    end

    subgraph Iceberg["ğŸ”· Apache Iceberg - Couche Transactionnelle"]
        META[MÃ©tadonnÃ©es]
        SNAP[Snapshots]
        SCHEMA[Ã‰volution SchÃ©ma]
    end

    subgraph Engines["âš™ï¸ Moteurs de Calcul (Au choix)"]
        SPARK[Spark]
        TRINO[Trino]
        FLINK[Flink]
    end

    subgraph Workloads["ğŸ“Š Cas d'Usage"]
        BI[BI/Reporting]
        ML[Machine Learning]
        STREAM[Streaming Temps RÃ©el]
    end

    Engines --> Iceberg
    Iceberg --> Storage
    Workloads --> Engines

    style Iceberg fill:#FF6B35,stroke:#333,stroke-width:3px
```

### Tableau de DÃ©cision pour Architectes

| Votre Besoin                      | Data Warehouse | Data Lake | Data Lakehouse |
| :-------------------------------- | :------------- | :-------- | :------------- |
| **Budget limitÃ© (>100 To)**       | âŒ             | âœ…        | âœ…             |
| **ConformitÃ© RGPD/CCPA**          | âœ…             | âŒ        | âœ…             |
| **Ã‰quipes multiples (BI + ML)**   | âš ï¸ Silos       | âš ï¸ Chaos  | âœ…             |
| **Ã‰volution de schÃ©ma frÃ©quente** | âŒ             | âš ï¸        | âœ…             |
| **Pas de vendor lock-in**         | âŒ             | âœ…        | âœ…             |

---

## 1.2 Qu'est-ce qu'Apache Iceberg ?

### DÃ©finition Simple

**Apache Iceberg** est une couche logicielle qui transforme vos fichiers Parquet/ORC/Avro sur S3/ADLS en une vraie table de base de donnÃ©es avec transactions, schÃ©ma, et historique.

**Ce n'est PAS** :

- âŒ Un moteur de calcul (comme Spark)
- âŒ Un systÃ¨me de stockage (comme S3)
- âŒ Un catalogue (comme Glue)

**C'est** :

- âœ… Un format de **mÃ©tadonnÃ©es** qui dÃ©crit comment organiser et lire vos fichiers
- âœ… Un **contrat** entre moteurs de calcul et donnÃ©es

### L'Histoire : NÃ© de la Douleur chez Netflix

En 2017, Netflix gÃ¨re 200+ Po de donnÃ©es sur S3 avec Apache Hive. Les problÃ¨mes sont critiques :

**ProblÃ¨me 1 : Performance**

```python
# Avec Hive
SELECT * FROM events WHERE date = '2023-01-15'
# â†’ Liste TOUS les fichiers dans s3://events/
#   (15 minutes pour 100M fichiers)
```

**ProblÃ¨me 2 : Pas d'atomicitÃ©**

```python
# Job Spark qui Ã©choue Ã  90%
spark.write.mode("append").parquet("s3://events/")
# â†’ 90% des fichiers Ã©crits, 10% manquants
# â†’ Table corrompue !
```

**ProblÃ¨me 3 : Partitionnement fragile**

```python
# Si vous oubliez de filtrer sur la partition...
SELECT * FROM events WHERE user_id = 123
# â†’ Full table scan (catastrophe !)
```

Ryan Blue et son Ã©quipe crÃ©ent Iceberg pour rÃ©soudre ces trois problÃ¨mes. Netflix open-source le projet en 2018. Il rejoint Apache en 2020.

Aujourd'hui, **Apple**, **Netflix**, **LinkedIn**, **Adobe**, et des centaines d'autres sociÃ©tÃ©s utilisent Iceberg en production.

### Comment Ã§a Marche : L'Innovation des MÃ©tadonnÃ©es

La diffÃ©rence fondamentale entre Hive et Iceberg :

**Approche Hive** :

```
s3://warehouse/events/
  â”œâ”€â”€ year=2023/
  â”‚   â”œâ”€â”€ month=01/
  â”‚   â”‚   â”œâ”€â”€ file1.parquet
  â”‚   â”‚   â””â”€â”€ file2.parquet
  â”‚   â””â”€â”€ month=02/
  â””â”€â”€ year=2024/
```

â†’ Pour lire, Hive liste **tous** les rÃ©pertoires (lent sur S3).

**Approche Iceberg** :

```
s3://warehouse/events/
  â”œâ”€â”€ metadata/
  â”‚   â”œâ”€â”€ v1.metadata.json (dÃ©crit la table)
  â”‚   â””â”€â”€ snap-123.avro (liste des fichiers)
  â””â”€â”€ data/
      â”œâ”€â”€ file-a.parquet
      â”œâ”€â”€ file-b.parquet
      â””â”€â”€ file-c.parquet
```

â†’ Iceberg lit `metadata.json`, sait **exactement** quels fichiers lire (rapide).

---

## 1.3 Les Avantages Concrets d'Apache Iceberg

### 1. Transactions ACID : Fini les DonnÃ©es Corrompues

**Situation rÃ©elle** : Un job Spark Ã©crit 1000 fichiers et plante au fichier 750.

**Avec Hive** :

- 750 fichiers Ã©crits et visibles
- 250 fichiers manquants
- Table inconsistante
- **Solution** : Effacer et tout relancer

**Avec Iceberg** :

- 750 fichiers Ã©crits physiquement
- Mais le snapshot n'est PAS validÃ©
- Les lecteurs ne voient **rien** (table stable)
- Relancez le job : il reprend de zÃ©ro

```sql
-- Les deux opÃ©rations sont atomiques
BEGIN;
  DELETE FROM events WHERE date < '2020-01-01';
  INSERT INTO events SELECT * FROM staging_events;
COMMIT;
-- âœ… Tout rÃ©ussit ou tout Ã©choue, jamais d'Ã©tat intermÃ©diaire visible
```

### 2. Ã‰volution de SchÃ©ma Sans RÃ©Ã©criture

**ScÃ©nario** : Votre application ajoute un champ `user_country`.

**Avec Hive** :

```sql
-- âŒ NÃ©cessite de recrÃ©er la table
CREATE TABLE events_v2 AS
SELECT *, NULL as user_country FROM events;
-- CoÃ»t : RÃ©Ã©crire 100 To
```

**Avec Iceberg** :

```sql
-- âœ… InstantanÃ© (mise Ã  jour de mÃ©tadonnÃ©es)
ALTER TABLE events ADD COLUMN user_country STRING;
-- CoÃ»t : <1 seconde, 0 rÃ©Ã©criture
```

**Bonus** : Les anciennes donnÃ©es retournent `NULL` pour la nouvelle colonne automatiquement.

### 3. Partitionnement MasquÃ© : ZÃ©ro Erreur Humaine

**Le piÃ¨ge classique avec Hive** :

```sql
-- Analyste oublie la clause de partition
SELECT COUNT(*)
FROM events
WHERE user_id = 123
-- âŒ Full scan de 500 To (facture de 5000$)
```

**Avec Iceberg** :

```sql
-- La table est partitionnÃ©e par DAY(event_time)
-- L'analyste Ã©crit juste :
SELECT COUNT(*)
FROM events
WHERE event_time BETWEEN '2024-01-01' AND '2024-01-31'
-- âœ… Iceberg applique automatiquement le partition pruning
-- Lit uniquement 31 partitions
```

Le partitionnement est une **propriÃ©tÃ© de la table**, pas une contrainte pour l'utilisateur.

### 4. Time Travel : Votre Machine Ã  Remonter le Temps

**Cas d'usage rÃ©els** :

**â‘  Reproduire un modÃ¨le ML** :

```sql
-- "Notre modÃ¨le de recommandation de dÃ©cembre donnait de meilleurs rÃ©sultats"
SELECT * FROM user_features
FOR SYSTEM_TIME AS OF '2024-12-01 00:00:00'
```

**â‘¡ Rollback aprÃ¨s une erreur** :

```sql
-- "On a accidentellement supprimÃ© 1M de lignes"
CALL system.rollback_to_snapshot('db.events', 8723648723648);
-- âœ… Retour en arriÃ¨re en 2 secondes
```

**â‘¢ ConformitÃ© et audit** :

```sql
-- "Montrez-moi la table telle qu'elle Ã©tait le jour de l'audit"
SELECT * FROM transactions
FOR SYSTEM_VERSION AS OF 982347982374;
```

---

## 1.4 L'Ã‰cosystÃ¨me d'un Lakehouse Iceberg

### Les 5 Couches d'une Architecture Iceberg

```mermaid
flowchart TB
    subgraph Layer5["Couche 5 - Consommation"]
        BI[ğŸ“Š PowerBI/Tableau]
        JUPYTER[ğŸ““ Jupyter Notebooks]
        API[ğŸ”Œ APIs MÃ©tier]
    end

    subgraph Layer4["Couche 4 - Moteurs de Calcul"]
        SPARK[âš¡ Spark<br/><i>Batch ETL</i>]
        FLINK[ğŸŒŠ Flink<br/><i>Streaming</i>]
        TRINO[ğŸš€ Trino<br/><i>SQL Ad-hoc</i>]
    end

    subgraph Layer3["Couche 3 - Catalogue"]
        CATALOG[ğŸ“š AWS Glue / Nessie<br/><i>Source de vÃ©ritÃ©</i>]
    end

    subgraph Layer2["Couche 2 - Table Format"]
        ICEBERG[ğŸ”· Apache Iceberg<br/><i>MÃ©tadonnÃ©es & Transactions</i>]
    end

    subgraph Layer1["Couche 1 - Stockage"]
        S3[â˜ï¸ S3 / ADLS / GCS<br/><i>Fichiers Parquet</i>]
    end

    Layer5 --> Layer4
    Layer4 --> Layer3
    Layer3 --> Layer2
    Layer2 --> Layer1

    style Layer2 fill:#FF6B35,stroke:#333,stroke-width:3px
    style Layer3 fill:#4ECDC4,stroke:#333,stroke-width:2px
```

### Description Pratique des Couches

| Couche           | Composant   | Ce qu'il fait                   | Exemple                       |
| :--------------- | :---------- | :------------------------------ | :---------------------------- |
| **Stockage**     | S3/ADLS/GCS | HÃ©berge les fichiers Parquet    | `s3://datalake/events/`       |
| **Table Format** | Iceberg     | GÃ¨re transactions & mÃ©tadonnÃ©es | Fichiers `.metadata.json`     |
| **Catalogue**    | Glue/Nessie | Pointe vers la version actuelle | `warehouse.prod.events â†’ v47` |
| **Compute**      | Spark/Trino | Lit et Ã©crit les donnÃ©es        | `SELECT * FROM events`        |
| **Consommation** | BI Tools    | Interface utilisateur           | Dashboards Tableau            |

### Exemple de Flux Concret

**ScÃ©nario** : IngÃ©rer des Ã©vÃ©nements et les requÃªter

**1. Ã‰criture (Spark/Flink)** :

```python
spark.table("events") \
     .write \
     .format("iceberg") \
     .mode("append") \
     .save()
# â†’ CrÃ©e des fichiers Parquet dans S3
# â†’ Met Ã  jour les mÃ©tadonnÃ©es Iceberg
# â†’ Enregistre un nouveau snapshot dans le catalogue
```

**2. Lecture (Trino)** :

```sql
-- Analyste utilise Trino
SELECT platform, COUNT(*)
FROM prod.events
WHERE date = CURRENT_DATE
GROUP BY platform;
# â†’ Trino lit le catalogue
# â†’ Lit les mÃ©tadonnÃ©es Iceberg
# â†’ Sait exactement quels fichiers Parquet lire
```

**3. La magie** : Spark et Trino travaillent sur les **mÃªmes donnÃ©es** sans conflit ni copie.

---

## 1.5 RÃ©sumÃ© : Pourquoi Iceberg Change la Donne

### Les 3 Valeurs Fondamentales

**1. InteropÃ©rabilitÃ©**

- Vos donnÃ©es ne sont plus liÃ©es Ã  un seul moteur
- Spark pour l'ingestion, Trino pour les requÃªtes, Flink pour le streaming
- Sur les **mÃªmes tables**

**2. FiabilitÃ©**

- Transactions ACID Ã©limine les corruptions
- Time travel pour rollback et audit
- ConformitÃ© rÃ©glementaire (GDPR, CCPA)

**3. SimplicitÃ© OpÃ©rationnelle**

- Ã‰volution de schÃ©ma sans downtime
- Partitionnement automatique
- Moins de maintenance, plus d'innovation

### Pour l'Architecte : Les Questions ClÃ©s

âœ… **Devriez-vous adopter Iceberg ?**

- Oui, si vous gÃ©rez >10 To de donnÃ©es analytiques
- Oui, si vous avez besoin de UPDATE/DELETE
- Oui, si vous voulez Ã©viter le vendor lock-in

âš ï¸ **Quand attendre ?**

- Vous avez <1 To de donnÃ©es (Parquet simple suffit)
- Votre stack est 100% propriÃ©taire (ex: uniquement Snowflake)

### Prochaine Ã‰tape

Le chapitre 2 plongera dans l'architecture interne d'Iceberg :

- Structure des mÃ©tadonnÃ©es
- Format des manifests
- MÃ©canismes de snapshot

Vous comprendrez **comment** Iceberg rÃ©alise ses promesses.
